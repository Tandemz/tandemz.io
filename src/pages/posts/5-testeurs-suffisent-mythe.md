---
og_image_width: 324
og_image_height: 216
hashtags:
- ux research
- user research
- 5 persons rule
- Nielsen
template: post
twitter_card: summary_large_image
ogtype: article
title: 5-testeurs-suffisent-mythe
full_title: "Tester avec 5 personne suffit-il vraiment ? \U0001F914"
date: 2022-10-04T22:00:00Z
thumb_img_path: "/images/5personstitle.jpg"
content_img_path: ''
excerpt: On entend partout que 5 personnes suffisent pour tester une interface ! Ce
  n'est pourtant pas aussi simple - ensemble, dÃ©mÃªlons le vrai du faux.
author: src/data/authors/francew.json
keywords: UX research, user research, usability testing, user tests, Nielsen, 5 persons
  rule, test sample size
ogimage: "/images/5personstitle-1.jpg"
beforeFooterSections: []

---
â€œQuelle est la taille de lâ€™Ã©chantillon que je dois prendre pour ma recherche utilisateur ?â€ - câ€™est probablement la question que lâ€™on pose le plus, surtout quand on dÃ©bute.

Elle se pose particuliÃ¨rement pour les Ã©tudes qualitatives, oÃ¹ on a toujours peur que les retours obtenus ne soient pas suffisamment nombreux pour prendre les bonnes dÃ©cisions. Et câ€™est lÃ  quâ€™un chiffre en particulier ne cesse de remonter : le fameux chiffre 5 !

5 utilisateurs suffiraient pour apprendre tout ce dont on a besoin dâ€™apprendre ğŸ¤”

Pourtant ce nâ€™est pas aussi simple : 5 nâ€™est pas un chiffre magique que lâ€™on peut sortir Ã  toutes les sauces et en toutes conditions, tous les experts sâ€™accordent lÃ  dessus. Mais ce mythe a la peau dure, et la communautÃ© a du mal Ã  sâ€™en dÃ©faire.

Aujourdâ€™hui, dÃ©mÃªlons le vrai du faux, pour essayer de trouver une rÃ©ponse satisfaisante Ã  notre question ! Il faudra pour cela aller jusque dans les fondements mathÃ©matiques de la thÃ©orie - si vous Ãªtes allergique aux mathÃ©matiques, pas de panique, sautez directement au segment â€œPour rÃ©sumerâ€ ;)

## Aux origines du mythes

En 1993, Jakob Nielsen (co-fondateur du cÃ©lÃ¨bre Nielsen Norman Group) et Thomas Landauer publient [**A mathematical model of the finding of usability problems**](https://dl.acm.org/doi/epdf/10.1145/169059.169166).

Ce papier de recherche est rÃ©sumÃ© en 2000 dans lâ€™article de blog [**Why You Only Need to Test with 5 Users**](https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/) qui fera le tour du monde - et est, Ã  bien des Ã©gards, considÃ©rÃ© comme Ã©tant Ã  lâ€™origine du mythe !

La conclusion de son article : **5 utilisateurs permettent de dÃ©couvrir 85% des problÃ¨mes dâ€™une interface.**

## Comprendre le papier dâ€™origine

Comme tout texte scientifique, pour bien en comprendre la conclusion il faut avoir en tÃªte les hypothÃ¨ses et le contexte sur lequel le texte se fonde.

### Cadre et dÃ©finitions

Dans leur papier, Nielsen et Landauer sâ€™intÃ©ressent uniquement aux **tests utilisateurs et aux** [**Ã©valuations heuristiques**](https://www.tandemz.io/posts/10-heuristiques-ux/), dont lâ€™objectif est selon eux de dresser **une liste la plus exhaustive possible de problÃ¨mes dâ€™utilisabilitÃ© survenant sur une interface**.

Un nouveau problÃ¨me remontÃ© = un Ã©lÃ©ment ajoutÃ© Ã  la liste.

Il nâ€™est jamais question ni de gravitÃ©, ni de frÃ©quence, ni dâ€™impact sur le besoin utilisateur.

Dâ€™ailleurs, ces deux mÃ©thodes sont catÃ©gorisÃ©es comme des **mÃ©thodes de debugging.**

### Objectif

Les auteurs cherchent Ã  trouver une faÃ§on **dâ€™optimiser les coÃ»ts dâ€™une Ã©tude dâ€™utilisabilitÃ©,** en optimisant le ratio **nombre de problÃ¨mes remontÃ©s / nombre de tests faits.**

Cet aspect financier est trÃ¨s important : ils y dÃ©dient 2 pages sur 7 de leur papier. En effet, Nielsen milite depuis 1989 pour la [Discount Usability](https://www.nngroup.com/articles/discount-usability-20-years/), une approche de la recherche utilisateur itÃ©rative et â€œquick and dirtyâ€, Ã  une Ã©poque oÃ¹ les mÃ©thodes de recherches sont trÃ¨s gÃ©nÃ©ralement soumises Ã  des notions de rigueurs statistiques hÃ©ritÃ©es de la recherche acadÃ©mique. Selon lui, la perte en fiabilitÃ© des donnÃ©es rÃ©coltÃ©es est largement compensÃ©e par la flexibilitÃ© quâ€™un format plus court et plus itÃ©ratif apporte - une notion peu acceptÃ©e de ses pairs en 1993.

### Constat

Nielsen et Landauer se basent sur la loi des rendements dÃ©croissants. Lâ€™idÃ©e est la suivante : si vous testez avec deux personnes, il est probable quâ€™une partie des problÃ¨mes quâ€™ils remontent soient les mÃªmes. Si vous testez avec une troisiÃ¨me personne, idem, elle remontra sÃ»rement des problÃ¨mes dÃ©jÃ  en partie Ã©tÃ© dÃ©tectÃ©s soit par le testeur 1, soit par le testeur 2, soit par les deux.

Par consÃ©quent, **plus on a de testeurs, plus on tombe souvent sur des problÃ¨mes dÃ©jÃ  rencontrÃ©s, et moins on dÃ©couvre des problÃ¨mes nouveaux.**

Ils vont donc chercher Ã  dÃ©terminer Ã  partir de combien de tests est-ce quâ€™il nâ€™est plus rentable de continuer dâ€™en faire, car le nombre de problÃ¨mes remontÃ©s sera trop faible par rapport Ã  lâ€™investissement (tant financier quâ€™en temps humain) que demande un test.

### ModÃ¨le mathÃ©matique

_Attention, câ€™est lÃ  quâ€™on rentre dans le dur du sujet ! Si vous nâ€™avez pas envie dâ€™entrer Ã  ce niveau de dÃ©tails, vous pouvez_ [_sauter directement Ã  nos conclusions_](#summary "Aller Ã  la conclusion") _! Promis, on ne dira rien_ ğŸ˜‰

Cette loi des rendements dÃ©croissants peut Ãªtre modÃ©lisÃ©e selon cette formule :

P = N(1-(1-L)^n)

avec :

* P le nombre de problÃ¨mes rencontrÃ©s
* N le nombre de problÃ¨mes au total
* n le nombre dâ€™utilisateurs avec qui on teste
* L la proportion moyenne de problÃ¨mes rencontrÃ©s par un utilisateur (si en moyenne chaque utilisateur remonte 20% des problÃ¨mes dâ€™une interface, et en rate 80%, alors L=0,2).

L Ã©tant une moyenne, pour augmenter la fiabilitÃ© du modÃ¨le, il faut que lâ€™Ã©chantillon dâ€™utilisateurs pour des tests soit Ã  peu prÃ¨s homogÃ¨ne, câ€™est-Ã -dire, quâ€™il sâ€™agisse dâ€™utilisateurs reprÃ©sentatifs de la mÃªme population.

### RÃ©sultat

Les auteurs **avancent empiriquement que L = 0,31** (31%), ce qui donne le graphique suivant :

![](/images/nielsenmodelgraph.png)

Effectivement, dâ€™aprÃ¨s ces rÃ©sultats, **avec n = 5, on trouve 85% des problÃ¨mes dâ€™une interface**. De plus, on voit bien que, au delÃ  de 5, chaque nouvel utilisateur avec qui on teste ne rapporte que peu de nouveaux problÃ¨mes dÃ©tectÃ©s (seulement +5% avec le testeurs 6, +3% avec le testeur 7, etc).

En rÃ©alitÃ©, le papier de 1993 nâ€™insiste pas tellement sur le chiffre de 5, mais plutÃ´t sur le modÃ¨le crÃ©Ã©, qui selon les auteurs doit servir de base pour aider les Ã©quipes de dÃ©veloppement Ã  prÃ©dire le bon nombre de tests pour faire avancer leur projet tout en optimisant le ROI de la recherche utilisateur.

Câ€™est surtout Nielsen qui pousse le chiffre 5, avec ses diffÃ©rents articles notamment ceux publiÃ©s en [2000](https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/), [2009](https://www.nngroup.com/articles/discount-usability-20-years/) et [2012](https://www.nngroup.com/articles/how-many-test-users/), dans lesquels il dit explicitement que **tester avec 5 utilisateurs suffit.**

## Les problÃ¨mes

Peut-Ãªtre que vous Ãªtes en train de vous dire : â€œMais du coup, je ne vois pas le problÃ¨me ! Le fondement mathÃ©matique derriÃ¨re ces dires semble solide !â€

Oui et non ! Il existe en fait deux catÃ©gories de problÃ¨mes qui font que cette affirmation - devenue axiome du monde de la recherche utilisateur depuis le temps - est en rÃ©alitÃ© un mythe :

* ceux liÃ©s Ã  une sur-simplification ou Ã  une mauvaise interprÃ©tation de cette thÃ©orie
* ceux liÃ©s aux limites mÃªmes du modÃ¨le de Nielsen et Landauer

### ProblÃ¨mes de sur-simplification

Souvenez-vous de vos cours de mathÃ©matiques. Vous avez sÃ»rement dÃ©jÃ  Ã©tÃ© reprisÂ·e par votre professeur pour avoir essayÃ© dâ€™appliquer un thÃ©orÃ¨me sans avoir vÃ©rifiÃ© dâ€™abord si les conditions du thÃ©orÃ¨me sâ€™appliquaient.

Eh bien, câ€™est souvent ce quâ€™il se passe quand on interprÃ¨te lâ€™affirmation : **tester avec** **5 utilisateurs suffit !**

Voici des erreurs communes que lâ€™on voit passer :

#### 1. **Appliquer la rÃ¨gle des 5 testeurs aux mauvaises mÃ©thodes**

Cette erreur survient dÃ¨s quâ€™on oublie que Nielsen parle de trouver **85% des problÃ¨mes dâ€™une interface lors de tests utilisateurs**.

La dÃ©marche qui lâ€™intÃ©resse est Ã  la fois Ã©valuative et qualitative, et ses rÃ©sultats ne peuvent ni sâ€™appliquer aux mÃ©thodes quantitatives, ni aux mÃ©thodes exploratoires.

Il faut donc Ã©viter :

* âŒ de faire des interviews avec uniquement 5 personnes : dans le cadre dâ€™interviews, lâ€™objectif est de comprendre lâ€™expÃ©rience, les motivations et besoins dâ€™une population. La nature des donnÃ©es est diffÃ©rente, et couvre des notions bien plus larges que celle de â€œproblÃ¨mes dâ€™une interfaceâ€. Il paraÃ®t donc logique quâ€™on ne puisse pas faire le tour dâ€™un sujet exploratoire en 5 personnes seulement. Lâ€™entreprise de Nielsen le dit elle-mÃªme, les interviews ne sont pas des tests dâ€™utilisabilitÃ©, et [5 interviews, ce nâ€™est pas suffisant.](https://www.nngroup.com/articles/interview-sample-size/) Mais du coup, quâ€™est-ce qui lâ€™est ? Il nâ€™existe pas de rÃ¨gle gÃ©nÃ©rale, si ce nâ€™est : arrÃªtez-vous quand vous aurez lâ€™impression de ne plus rien apprendre. Cela peut arriver au bout de 10 interviews, comme cela peut arriver au bout de 50.
* âŒ de faire des tests non-modÃ©rÃ©s avec uniquement 5 personnes : lâ€™objectif et les mesures ne sont pas les mÃªmes, et la rÃ¨gle des 5 ne sâ€™applique donc pas. LÃ  oÃ¹ lâ€™objectif de Nielsen, en test qualitatif est dâ€™obtenir une liste de problÃ¨mes, son objectif en quanti est plutÃ´t de savoir combien rencontrent ce problÃ¨me, Ã  quelle Ã©chelle, avec quel impact, Ã  travers des mesures de durÃ©e, de frÃ©quence etc. Ces mesures ont dâ€™avantage le besoin dâ€™Ãªtre fiables statistiquement, et ainsi la recommandation de Nielsen lui mÃªme est de passer plutÃ´t Ã  [20 testeurs](https://www.nngroup.com/articles/quantitative-studies-how-many-users/), ou \[40, selon la marge dâ€™erreur que vous Ãªtes prÃªtÂ·e Ã  accepter\]([https://www.nngroup.com/articles/summary-quant-sample-sizes/#:\~:text=Summary%3A](https://www.nngroup.com/articles/summary-quant-sample-sizes/#:\~:text=Summary%3A "https://www.nngroup.com/articles/summary-quant-sample-sizes/#:~:text=Summary%3A")[ 40 participants is an,you can recruit fewer users.)](https://www.nngroup.com/articles/summary-quant-sample-sizes/#:\~:text=Summary%3A%2040%20participants%20is%20an,you%20can%20recruit%20fewer%20users.)).
* âŒ de faire des questionnaires avec uniquement 5 personnes : mÃªme si cela paraÃ®t pour la plupart complÃ¨tement logique, rappelons-le tout de mÃªme ! Avec un questionnaire, lâ€™objectif est souvent de pouvoir extrapoler les rÃ©sultats obtenus auprÃ¨s dâ€™un Ã©chantillon Ã  une population plus large. La signification statistique de cet Ã©chantillon devient alors essentielle. Heureusement, de nombreux [calculateurs en ligne](https://www.surveymonkey.com/mp/sample-size-calculator/) peuvent vous aider Ã  en dÃ©terminer la bonne taille.

_ğŸ¤” A noter : on parle depuis le dÃ©but de mÃ©thodes de recherche appliquÃ©es Ã  de lâ€™interface. Est-ce que la thÃ©orie de Nielsen sâ€™applique aussi au test dâ€™objets physiques ou de services ? Peut-on trouver 85% des problÃ¨mes dâ€™ergonomie dâ€™un siÃ¨ge, ou des frictions rencontrÃ©es par un voyageur Ã  lâ€™aÃ©roport, avec 5 participants ? Malheureusement, lors de la rÃ©daction de cet article, nous nâ€™avons pas trouvÃ© dâ€™Ã©lÃ©ments de rÃ©ponse Ã  cette question en particulier ! Affaire Ã  suivreâ€¦_

#### 2. Prendre nâ€™importe quelles 5 personnes

Nielsen le mentionne uniquement de faÃ§on passagÃ¨re dans son papier de recherche et dans son article, sÃ»rement parce que câ€™est un fondement de la recherche utilisateur quâ€™il nâ€™a pas jugÃ© utile de rÃ©pÃ©ter - cependant, il aurait probablement du !

Pour que la recherche utilisateur soit valide (quelle que soit la mÃ©thode), il faut que les utilisateurs soient **reprÃ©sentatifs de la cible** du produit testÃ©.

Ainsi quand on dit â€œtester avec 5 utilisateurs suffit !â€ on dit bien **utilisateur** (ou Ã  la rigueur, potentiel utilisateur), et non â€œpersonneâ€.

Si vous testez votre application de recherche dâ€™emploi avec vos parents Ã  la retraite depuis 10 ans, vous pouvez Ãªtre sÃ»rÂ·e que vous nâ€™obtiendrez pas des rÃ©sultats aussi exhaustifs ni aussi pertinents que si vous testiez avec des personnes en recherche dâ€™emploi en ce moment mÃªme.

<p style="background-color:#E3F4FF;padding:16px;border-radius:4px;">ğŸ’¡ Trouver des utilisateurs reprÃ©sentatifs de votre cible vous paraÃ®t plus facile Ã  dire quâ€™Ã  faire ? Laissez-nous vous aider ! Chez Tandemz, câ€™est notre spÃ©cialitÃ© ! Vous ne nous croyez-pas ? [Jetez un oeil aux recrutements passÃ©s que nous avons dÃ©jÃ  effectuÃ©s ! ](https://www.tandemz.io/posts/tandemz-past-recruitment-database/)</p>

#### 3. Tester avec 5 utilisateurs aux profils trop diffÃ©rents

Le modÃ¨le de Nielsen ne fonctionne rÃ©ellement que si les utilisateurs qui testent sont reprÃ©sentatifs de la mÃªme cible.

_Note : il nâ€™explique pas exactement pourquoi dans son texte, mais cela doit Ãªtre du au fait que dans sa formule, un Ã©lÃ©ment important est la variable L, la proportion moyenne de problÃ¨mes rencontrÃ©s par un utilisateur. Or, pour que cette moyenne fasse rÃ©ellement sens, il faut que les utilisateurs aient des profils et des comportements comparables. Sinon, câ€™est comme dire quâ€™un fruit pÃ¨se en moyenne 500g, sans distinguer les pommes des pastÃ¨ques !_

Ce point est souvent nÃ©gligÃ©, et il nâ€™est du coup pas rare de voir des Ã©tudes faites avec 5 personnes, chaque personne devant reprÃ©senter Ã  elle seule toute une cible. En rÃ©alitÃ©, si vous avez plusieurs cibles (par exemple, une cible dâ€™utilisateurs finaux et une cible dâ€™administrateurs, ou mÃªme, une cible jeune et une cible plus Ã¢gÃ©e), il faudrait tester avec 5 personnes de chaque cible pour rÃ©ellement appliquer les recommandations de Nielsen.

#### 4. Faire un test de 5 personnes et sâ€™arrÃªter lÃ 

Comment mentionnÃ© plus haut, lâ€™objectif premier de Nielsen Ã©tait de maximiser le ROI des tests dâ€™usabilitÃ©. En effet, dans les annÃ©es 90, il cherche Ã  pousser les entreprises qui nâ€™ont ni les moyens ni le temps de faire de la recherche dâ€™en faire quand mÃªme - quitte Ã  Ãªtre moins rigoureux sur les mÃ©thodes traditionnelles. **Mais Ã  une condition : itÃ©rer !**

Dans cette mÃªme veine, Nielsen a toujours recommandÃ© de faire de **multiples itÃ©rations de 5 tests**. En effet, dans un contexte oÃ¹ les interfaces Ã©voluent trÃ¨s vite, il devient inutile de dresser en une fois une liste trÃ¨s exhaustive des problÃ¨mes dâ€™utilisabilitÃ© dâ€™un produit : il est probable que de toute faÃ§on, lâ€™Ã©quipe de dÃ©veloppement ne puisse pas la rÃ©soudre dans son intÃ©gralitÃ©, rendant cette liste rapidement obsolÃ¨te aux grÃ©s des Ã©volutions de lâ€™interface. Il faut ainsi privilÃ©gier un suivi continu mais moins exhaustif, pour pouvoir aider les choix des Ã©quipes de dÃ©veloppement sur la durÃ©e.

<p style="background-color:#E3F4FF;padding:16px;border-radius:4px;">ğŸ’¡ ItÃ©rez rapidement et facilement avec nos offres de crÃ©dits Tandemz! Lâ€™achat de crÃ©dits prÃ©payÃ©s vous permet de faire des Ã©conomies et dâ€™accÃ©lÃ©rer vos cycles de recherche, tout en vous Ã©vitant la dÃ©multiplication des allers-retours de facturation. Pour plus dâ€™infos, [contactez-nous](/contact "Contactez-nous") ! </p>

Ainsi dÃ¨s le dÃ©part, lâ€™affirmation â€œ**5 utilisateurs permettent de dÃ©couvrir 85% des problÃ¨mes dâ€™une interfaceâ€** vient avec son lot dâ€™astÃ©risques, de â€œsiâ€œ et de â€œmaisâ€, qui ne la rendent pas applicable universellement. Malheureusement, et comme trop bien souvent, la communautÃ© sâ€™est avant tout emparÃ©e dâ€™une forme simpliste et fausse du modÃ¨le.

Mais mÃªme si on prend bien en compte toutes ces nuances et paramÃ¨tres, est-ce que le modÃ¨le de Nielsen est rÃ©ellement 100% fiable ?

### Les limites du modÃ¨le

#### Est-ce que L = 0.31 est vraiment gÃ©nÃ©ralisable ?

Pour rappel, Nielsen avance empiriquement que, en moyenne, un utilisateur va trouver 31% des problÃ¨mes dâ€™une interface. Câ€™est de cette hypothÃ¨se appliquÃ©e Ã  son modÃ¨le que dÃ©coule lâ€™affirmation â€œ5 utilisateurs dÃ©couvrent 85% des problÃ¨mes dâ€™une interfaceâ€.

Si en fait L=0.2 (donc un utilisateur trouve 20% des problÃ¨mes), le chiffre pour trouver 85% des problÃ¨mes passe de 5 Ã  9. Câ€™est presque le double ! Et avec 5 personnes, on ne trouve finalement plus que 67% des problÃ¨mes.

Or, cette variable L dÃ©pend en rÃ©alitÃ© de nombreux facteurs :

* du type dâ€™utilisateurs (sont-ils novices ou plutÃ´t habituÃ©s de cette interface ?)
* de la complexitÃ© de lâ€™interface testÃ©e, et du scope des tÃ¢ches du test
* du niveau dâ€™itÃ©ration de lâ€™interface (en effet, si une interface est dÃ©jÃ  passÃ©e par des itÃ©rations de tests et dâ€™amÃ©liorations, thÃ©oriquement cela veut dire que les problÃ¨mes les plus Ã©vidents ont dÃ©jÃ  Ã©tÃ© repÃ©rÃ©s et corrigÃ©s - ne restent plus que les problÃ¨mes plus subtils et donc moins dÃ©tectables)
* du niveau de lâ€™Ã©valuateur

Il nâ€™y a donc aucune raison de penser que L=0.31 est vraiment gÃ©nÃ©ralisable.

Cela veut dire que pour utiliser de faÃ§on vraiment fiable la formule de Nielsen, il faudrait pouvoir calculer L. Sauf que, pour calculer L, il faut connaÃ®tre le nombre total de problÃ¨mes dans lâ€™interface ! Un nombre quâ€™on ne connaÃ®t a priori pas, puisque tout lâ€™intÃ©rÃªt de la dÃ©marche de test dâ€™utilisabilitÃ© est de les dÃ©couvrir.

#### Empiriquement, Ã§a ne marche pas tout Ã  fait

Plusieurs Ã©tudes qui ont suivi les travaux de Nielsen et Landauer ont eu pour dÃ©marche de tester un site avec un certain nombre dâ€™utilisateurs, et de voir quelle proportion de problÃ¨mes ils auraient rÃ©ellement trouvÃ©s sâ€™ils sâ€™Ã©taient arrÃªtÃ©s Ã  5. Or surprise : on en trouve rarement 85% !

Celle que nous avons trouvÃ© la plus intÃ©ressante (car il serait trop long de toutes les rÃ©sumer) est la suivante :

En 2002, Faulkner publie un [papier de recherche](https://link.springer.com/content/pdf/10.3758/BF03195514.pdf), dans lequel elle a rÃ©alisÃ© des tests avec 60 utilisateurs. Puis, Ã  lâ€™aide dâ€™un logiciel, elle a crÃ©Ã© 100 sÃ©lections alÃ©atoires, en sets de respectivement 5, 10, 15 et 20 participants, pour ainsi simuler ce quâ€™il se serait passÃ© si elle nâ€™avait testÃ© quâ€™avec ces participants.

Pour les sets de 5, elle remarque ainsi que selon les utilisateurs sur lesquels elle serait tombÃ©e, elle aurait pu espÃ©rer trouver entre 55% et 100% des problÃ¨mes - ce qui prÃ©sente une variance Ã©norme ! A noter tout de mÃªme que, en moyenne sur les 100 sets de 5 utilisateurs, elle trouvait bien 85% des problÃ¨mes de lâ€™interface.

![](/images/5testersset.png)

Pour les sets de 10 utilisateurs, elle Ã©tait plutÃ´t entre 82% et 100%, avec une moyenne de 95%

![](/images/10testersset.png)

Et ainsi de suite :

![](/images/allsets.png)

Cette Ã©tude corrobore bien le modÃ¨le de Nielsen et Landauer, mais uniquement en moyenne ! RamenÃ©e au cas rÃ©el dâ€™une Ã©tude terrain, cette moyenne ne peut pas malheureusement pas sâ€™appliquer.

La rÃ©alitÃ© est donc plutÃ´t la suivante : **avec 5 utilisateurs, vous trouverez entre 55% et 100% des problÃ¨mes de votre interface !** A vous de voir ensuite si cet intervalle de taux est acceptable ou non.

#### Quid de la sÃ©vÃ©ritÃ© des problÃ¨mes ?

Le modÃ¨le de Nielsen et Landauer ne se pose pas du tout la question de la sÃ©vÃ©ritÃ© dâ€™un problÃ¨me. DÃ©couvrir 85% des problÃ¨mes, cela ne veut pas dire dÃ©couvrir 85% des problÃ¨mes les plus graves ni les plus bloquants !

On pourrait croire que plus un problÃ¨me est bloquant, plus il est Ã©vident, et donc plus il sera vu rapidement. Câ€™est dâ€™ailleurs la thÃ©orie de Virzi de 1990 - or Nielsen et Landauer se sont beaucoup appuyÃ©s sur ses travaux pour crÃ©er leur modÃ¨le.

Pourtant, il a depuis Ã©tÃ© plutÃ´t [thÃ©orisÃ©](https://measuringu.com/problem-severity/) quâ€™il nâ€™y a en fait aucune corrÃ©lation entre sÃ©vÃ©ritÃ© et dÃ©couvrabilitÃ© dâ€™un problÃ¨me.

La question de la sÃ©vÃ©ritÃ© se pose du coup plutÃ´t dans lâ€™autre sens : si 5 utilisateurs dÃ©couvrent 85% des problÃ¨mes, et quâ€™il y a une probabilitÃ© non nulle que parmi les 15% restants, il y ait des problÃ¨mes graves, est-ce vraiment acceptable de sâ€™arrÃªter lÃ  ? On pourrait par exemple donner lâ€™exemple des produits avec des applications mÃ©dicales ou de navigation, oÃ¹ le moindre dÃ©faut de conception ou de dÃ©veloppement peut Ã©ventuellement mettre en danger le bien-Ãªtre voire la vie de leurs usagers.

## Pour rÃ©sumer

<div id="summary"> Lâ€™affirmation â€œTester avec 5 personnes suffitâ€ nâ€™est pas complÃ¨tement fausse - elle est juste trÃ¨s imprÃ©cise, et surtout, elle vient avec beaucoup de limites et de conditions quâ€™il est facile dâ€™oublier ! </div>

Lâ€™affirmation complÃ¨te devrait plutÃ´t Ãªtre : **Tester avec 5 utilisateurs permet de trouver entre 55% et 100% des problÃ¨mes dâ€™une interface.**

Mais attention, pour que cette affirmation soit rÃ©ellement valable, il faut :

* âœ… Vous placer dans le cadre de **tests dâ€™utilisabilitÃ© dâ€™une interface.**  
  âŒ Nâ€™essayez pas de lâ€™appliquer aux interviews exploratoires ni aux mÃ©thodes quantitatives !
* âœ… Tester avec 5 utilisateurs dans la **cible de votre produit**  
  âŒ Avec des personnes Ã  qui votre produit ne sâ€™adresse pas, les taux de problÃ¨mes dÃ©couverts sont encore plus bas.
* âœ… Tester avec 5 utilisateurs **au profil et aux comportements similaires**  
  âŒ En prenant 5 utilisateurs trop diffÃ©rents, la fourchette de problÃ¨mes rencontrÃ©s devient carrÃ©ment alÃ©atoire.
* âœ… Sâ€™assurer que chaque utilisateur trouve environ 30% des problÃ¨mes dâ€™une interface   âŒ En pratique, ce chiffre est non seulement trÃ¨s difficile Ã  vÃ©rifier, il est aussi trÃ¨s variable. Or, moins vos utilisateurs trouvent de problÃ¨mes, plus il vous en faut pour vos tests !
* âŒ Oublier les notions de frÃ©quences ou de criticitÃ© des problÃ¨mes. AprÃ¨s 5 tests, vous avez tout de mÃªme la possibilitÃ© dâ€™Ãªtre passÃ©Â·e Ã  cÃ´tÃ© de problÃ¨mes bloquants ou graves.

## Si ce nâ€™est pas 5, alors combien ?

Malheureusement, la seule vraie rÃ©ponse est : Ã§a dÃ©pend !

Eh oui, les facteurs qui influent sur la qualitÃ©, la pertinence et lâ€™exhaustivitÃ© des retours sont tellement nombreux, quâ€™en rÃ©alitÃ©, le seul moyen de savoir si on en a fait assez, câ€™estâ€¦ dâ€™en avoir fait assez pour sâ€™en rendre compte ! Comme pour les interviews, Ã  partir du moment oÃ¹ vous nâ€™obtenez plus de retour nouveau, vous pouvez probablement considÃ©rer que vous avez fait le tour du sujet.

Oui on sait, cette rÃ©ponse apporte trÃ¨s peu satisfactionâ€¦ Et câ€™est bien lÃ  le problÃ¨me : le manque de rÃ©ponse dÃ©finitive donne vraiment envie dâ€™adhÃ©rer Ã  cette thÃ©orie, si simple et si mÃ©morable, du â€œ5 utilisateurs suffisentâ€ - et câ€™est pour Ã§a que le mythe sâ€™est rÃ©pandu aussi vite !

Mais finalement, est-ce que câ€™est la bonne question Ã  se poser ?

Le modÃ¨le de Nielsen est avant tout un modÃ¨le dâ€™optimisation du ROI de la recherche. Il nâ€™a jamais rÃ©ellement Ã©tÃ© question de savoir combien de personnes permettent de trouver combien de problÃ¨me - mais plutÃ´t, dâ€™accepter que :

* plus vous testez, plus cela vous coÃ»tera cher, en temps comme en argent - et ce coÃ»t nâ€™est pas linÃ©aire, mais plutÃ´t exponentiel, Ã  cause de la redondance que vous allez avoir au cours des tests
* moins vous testez, moins vous comprendrez ce quâ€™il faut amÃ©liorer sur le produit, et plus vous avez de chance de laisser passer des problÃ¨mes qui peuvent sâ€™avÃ©rer graves.

Le tout est de trouver un bon Ã©quilibre entre efforts de recherche et exhaustivitÃ© des rÃ©sultats - et dâ€™accepter les consÃ©quences de son choix.

Notre conseil ? DÃ©finissez dâ€™abord votre prioritÃ© ainsi que le niveau de risque acceptable associÃ© ! Posez-vous ainsi les questions suivantes :

* Un problÃ¨me sur votre produit ou parcours peut-il avoir un impact grave sur vos utilisateurs ? Si oui, alors privilÃ©giez lâ€™exhaustivitÃ©.
* Si non, avez-vous le budget et le temps de tester avec 15 personnes ? 10 personnes ? 5 personnes ? Si non, contentez-vous de ce que vous pouvez rÃ©aliser comme tests, et essayez dâ€™itÃ©rer le plus souvent possible pour compenser.
* Si oui, et que ces personnes remontent beaucoup de problÃ¨mes, aurez-vous la capacitÃ© de dÃ©veloppement pour les corriger rapidement avant votre prochain cycle de test ? Ajustez alors la nombre de personnes visÃ©es en fonction de votre capacitÃ© de dÃ©veloppement.